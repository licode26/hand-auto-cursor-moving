# hand-auto-cursor-moving


This project implements an AI-powered auto cursor movement system that allows users to control the mouse pointer without touching the physical device. By leveraging real-time facial landmark detection through a webcam, the system tracks specific facial points (like the nose tip or eye center) and maps their position to the screen coordinates, moving the cursor accordingly.

The solution is built using Python and integrates:

OpenCV for video capture and image processing,

MediaPipe for real-time face mesh/landmark tracking, and

PyAutoGUI for controlling the mouse cursor.

This tool can serve as an assistive technology for physically challenged users, enable touchless computer interaction, or be extended to support gesture-based clicking, blink detection for left/right clicks, or even hand tracking.

ðŸ§  Key Features:
Real-time facial landmark detection

Cursor movement based on nose or eye position

Python-based lightweight implementation

Works with any standard webcam

Cross-platform support

ðŸ’¡ Applications:
Accessibility tools for differently-abled users

Hands-free control in medical or clean-room environments

Gaming or interactive art installations

Smart kiosks and AI-driven interfaces

Would you like a readme.md version or poster content for a project display as well?









![image](https://github.com/user-attachments/assets/0b75f360-7c97-4893-b6ef-cc5dcc88a449)
